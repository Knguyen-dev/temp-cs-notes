// stdlib
#include <assert.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h>
#include <stdio.h>
#include <errno.h>
// system
#include <fcntl.h>
#include <poll.h>
#include <unistd.h>
#include <arpa/inet.h>
#include <sys/socket.h>
#include <netinet/ip.h>
// C++
#include <string>
#include <vector>
// proj
#include "hashtable.h"

/**
 * We're using intrusive data structures. Due to how structures are laid out in memory, we can get the pointer 
 * of the embedded data structure, do some pointer arithmetic, and return a pointer that points to the outer 
 * data structure (the container). Pretty clever trick
 * 
 */
#define container_of(ptr, T, member) \
    ((T *)( (char *)ptr - offsetof(T, member) ))


static void msg(const char *msg) {
    fprintf(stderr, "%s\n", msg);
}

static void msg_errno(const char *msg) {
    fprintf(stderr, "[errno:%d] %s\n", errno, msg);
}

static void die(const char *msg) {
    fprintf(stderr, "[%d] %s\n", errno, msg);
    abort();
}

/*
* This code sets the socket in non-blocking mode. So reads and writes, whether blocking or non-blocking are the same sys calls. However if we set the socket to non-blocking, we 
* actually affect the internal behavior of those syscalls. If read-buffer isn't empty, both blocking/non-blocking will return data. However when empty, reading on a blocking socket 
* will make the socket wait for more data. However if you're reading with the non-blocking socket, the read call will raise an error if it detects that proceeding with the read call will 
* cause blocking. This is very helpful as it prevent us from reading and blocking the MAIN thread. A similar idea can be applied when writing. If the the OS-sender buffer isn't full, 
* both blocking/non-blocking writes will be able to copy data into the buffer. However if the buffer is full, calling write() with a blocking socket will wait until the buffer isn't full 
* and has room for that data, blocking the main thread for a bit. On the other hand, calling write() with a non-blocking socket will simply raise an error if it detects that the write will 
* block the main thread. As a result we prevent wasting time.
*/
static void fd_set_nb(int fd) {
    errno = 0;
    int flags = fcntl(fd, F_GETFL, 0);
    if (errno) {
        die("fcntl error");
        return;
    }

    flags |= O_NONBLOCK;

    errno = 0;
    (void)fcntl(fd, F_SETFL, flags);
    if (errno) {
        die("fcntl error");
    }
}

/**
 * Shift 32 to the left by 20 by 20 bits. This makes the thing 32 MB. You can easily calculate 
 * this by doing 32 * 2^{20}. 
 * 
 * When a socket is created the OS creates a socket receive and socket send buffer for incoming and outgoing data.
 * We've covered this, however the typical buffer sizes on many systems is about 64 KB to 512 KB, which is a lot less
 * than 32 MB. So we'll be storing data from that OS buffer into our user-defined buffer, and our user-defined buffer is like 
 * many times bigger.
 * 
 * The motivation behind making the max message size so big, is that we want the application to handle very large messages, even 
 * if the kernel only able to at most give us a part of the message at a time. So the receive buffer could be fill, we send it to our 
 * user-defined buffer, and maybe that has to happen a couple of times for the entire message to be received. It's a big indicator that 
 * our application is ready to handle partial reads and writes.
 */
const size_t k_max_msg = 32 << 20;  // likely larger than the kernel buffer

struct Conn {
    int fd = -1;
    // application's intention, for the event loop
    bool want_read = false;
    bool want_write = false;
    bool want_close = false;
    // buffered input and output
    Buffer incoming;  // data to be parsed by the application
    Buffer outgoing;  // responses generated by the application
};

typedef std::vector<uint8_t> Buffer;

// append to the back
static void buf_append(Buffer &buf, const uint8_t *data, size_t len) {
    buf.insert(buf.end(), data, data + len);
}

// remove from the front
static void buf_consume(Buffer &buf, size_t n) {
    buf.erase(buf.begin(), buf.begin() + n);
}

/*
* + Application callback when listening socket is ready:
* So what we mean by this is that this is the code we call when the listening socket 
* is ready to be read. The idea is to create the TCP connection socket by extracting a pending TCP connection from the listening socket's backlog. The main idea here is 
* to construct and return a Connection object that satisfies 2 conditions:
* 
* 1. It contains the fd for the TCP connection socket, allowing us to reference it later when doing read or write operations
* 2. We want the want_read flag to be set as true. This needs to be set initially because in order to process a request, we need to read data from that request. Notice that we 
* leave want_write = false, because we don't want to write yet. Of course, this affects the flags on the poll obj, and what statuses we query for.
* 
* So the main takeaway is that these application callbacks are going to be directly working with these connection objects. Changing the values in the incoming and outgoing user defined 
* buffers, changing the values on the booleans as well.
*/
static Conn *handle_accept(int fd) {
    // accept
    struct sockaddr_in client_addr = {};
    socklen_t addrlen = sizeof(client_addr);
    int connfd = accept(fd, (struct sockaddr *)&client_addr, &addrlen);
    if (connfd < 0) {
        msg_errno("accept() error");
        return NULL;
    }
    uint32_t ip = client_addr.sin_addr.s_addr;
    fprintf(stderr, "new client from %u.%u.%u.%u:%u\n",
        ip & 255, (ip >> 8) & 255, (ip >> 16) & 255, ip >> 24,
        ntohs(client_addr.sin_port)
    );

    // set the new connection fd to nonblocking mode
    fd_set_nb(connfd);

    // create a `struct Conn`
    Conn *conn = new Conn();
    conn->fd = connfd;
    conn->want_read = true;
    return conn;
}

// The maximum number of arguments we'll accept within a single message I think
const size_t k_max_args = 200 * 1000;

/**
 * This function reads 4 bytes from a byte buffer (represented by the `cur` pointer)
 * and stores them as a 32-bit unsigned integer in `out`.
 * 
 */
static bool read_u32(const uint8_t *&cur, const uint8_t *end, uint32_t &out) {
    if (cur + 4 > end) {
        return false;
    }
    memcpy(&out, cur, 4);
    cur += 4;
    return true;
}

/*
* Reads n bytes from a byte buffer (pointed to by cur) into the out string.  
* 
* Even though cur is a `const uint8_t *`, std::string has constructors and the assign function takes raw character data. We also know that `uint8_t` is just an alias for 
* `unsigned char` so this is valid. It interprets the data as a sequence of bytes and stores those as is in
* std::string. So we're storing the bytes that represents the characters in the string. Pointer arithmetic is being used, but assign() takes two positions in a buffer, 
* and values the elements in between. I mean look at this similar but more understandable example:
* 
* const char buffer[] = { 'H', 'i', '!', '\0', 'X', 'Y' };
* const char* cur = buffer;
* std::string out;
* out.assign(cur, cur + 3);  // "Hi!"
*/
static bool read_str(const uint8_t *&cur, const uint8_t *end, size_t n, std::string &out) {
    if (cur + n > end) {
        return false;
    }
    out.assign(cur, cur + n);
    cur += n;
    return true;
}

// 
// 
// 

/**
 * Parses the data from a single request/message.
 * 
 * + Parameter:
 * - data: Pointer to the start of the message (a byte array)
 * - size: The size of the entire message (header + payload) 
 * 
 * + Again we're dealing with tag-length-value format:
 * +------+-----+------+-----+------+-----+-----+------+
 * | nstr | len | str1 | len | str2 | ... | len | strn |
 * +------+-----+------+-----+------+-----+-----+------+
 * So like the first string could be "GET" the second string could 
 * be a key "num_people". So it's two strings. But we'll still put things in 
 * this format.
 * 
 */
static int32_t parse_req(const uint8_t *data, size_t size, std::vector<std::string> &out) {

    // 1. Pointer to the end of the byte array. This should be the last element of the byte array.
    // 2. Read 4 bytes from the data buffer and store that into the nstr variable
    // Remember this is the header of the message that represents the number of strings that are in our message.
    const uint8_t *end = data + size;
    uint32_t nstr = 0;
    if (!read_u32(data, end, nstr)) {
        return -1;
    }

    // If the number of strings/args bigger than that we've allowed, if so then fail the request
    // Again those 32 bits represent an integer so that's the comparison is happening here.
    if (nstr > k_max_args) {
        return -1;  // safety limit
    }

    // Whilst our output buffer doesn't have the expected number of arguments stored in it.
    while (out.size() < nstr) {
        // Read 4 bytes to get the length of the string and store that in len
        // Note: So I guess len is converted to a size_t interpreting those 4 bytes as an integer.
        // Telling us how many bytes to read to get the actual string payload.
        uint32_t len = 0;
        if (!read_u32(data, end, len)) {
            return -1;
        }
        
        // Push an empty string object at the back of our vector. Then we'll need 
        // Read len bytes from our byte array and store it in that string object.
        out.push_back(std::string());
        if (!read_str(data, end, len, out.back())) {
            return -1;
        }
    }

    // At this point, we've processed `nstr` strings. Each string (8 bytes of data), we followed the amount of bytes to copy to get 
    // the string. When doing those read_u32 and read_str, those functions advanced the data pointer.
    // If the data pointer isn't pointing to the end, even though we followed the protocol, this message is formatted incorrectly
    // and there's some trailing data at the end so fail the request. We should ideally be pointing at the end if everything was right.
    if (data != end) {
        return -1;  // trailing garbage
    }
    return 0;
}

// For error responses: error code for TAG_ERR
enum {
  ERR_UNKNOWN = 1,    // unknown command
  ERR_TOO_BIG = 2,    // response too big
};

// For good responses: data types of serialized data
enum {
  TAG_NIL = 0,    // nil
  TAG_ERR = 1,    // error code + msg
  TAG_STR = 2,    // string
  TAG_INT = 3,    // int64
  TAG_DBL = 4,    // double
  TAG_ARR = 5,    // array
};

// **** Helpful functions for serialization ****
/**
 * These functions handle appending bytes (that represent integers) into 
 * a buffer. 
 * 
 * + buf_append_u8: Append 1 byte into the buffer
 * + buf_append_u32: Append 4 bytes into the buffer
 * + buf_append_i64: Append a 64bit integer into the buffer. To do this,
 * it casts it into a pointer to a buffer of unsigned bytes. 
 * 
 * + buf_append_dbl: Appends a double into our buffer. It does this by 
 * casting that double as a pointer to a buffer of unsigned bytes.
 * 
  * For signed values like int64_t, even though we're casting to uint8_t* (which is unsigned),
 * we're not losing any information—we're just viewing the memory as raw bytes.
 *
 * From the start, we know that the data we're working with is an integer,
 * represented by a fixed number of bits. When we cast a uint32_t into a uint8_t*,
 * we're essentially interpreting that 32-bit integer as an array of 4 unsigned bytes.
 * Since a pointer can be seen as pointing to the start of an array, this works naturally.
 *
 * We use the same approach for int64_t, which is a 64-bit signed integer.
 * We're just treating its memory representation as an array of 8 unsigned bytes.
 * No data is lost because we're not changing the value—just how we access the bits.
 *
 * The reason a 64-bit integer can represent negative values is because of two's complement
 * encoding, where the leftmost bit serves as the sign bit. This doesn't affect how we
 * serialize the data into bytes—it only matters when the bytes are interpreted again.
 *
 * So it's the client's responsibility to understand how to decode the binary data.
 * If the client knows that a field represents a signed 64-bit integer, it should
 * interpret the bytes using two's complement rules.
 *
 * One more thing to consider is endianness. Most machines today are little-endian,
 * meaning the least significant byte comes first in memory. However, network communication 
 * often use big-endian (network byte order). So if we're sending this data over the 
 * network, we'll need to convert it from little-endian to big-endian first. I know I probably
 * already talked about this, but since we're running this locally, the client and server are just 
 * different processes on our machine, no transmission over the actual network is happening, so we 
 * can keep things in little endian rather than converting into or from Big Endian.
 */
static void buf_append_u8(Buffer &buf, uint8_t data) {
  buf.push_back(data);
}
static void buf_append_u32(Buffer &buf, uint32_t data) {
  buf_append(buf, (const uint8_t *)&data, 4);
}
static void buf_append_i64(Buffer &buf, int64_t data) {
  buf_append(buf, (const uint8_t *)&data, 8);
}
static void buf_append_dbl(Buffer &buf, double data) {
  buf_append(buf, (const uint8_t *)&data, 8);
}

/**
 * + out_nil:
 * Appends 1 byte to our output buffer. This one byte
 * is represented as TAG_NIL, which is just the integer 0, and it just 
 * represents that we're returning nothing.
 * 
 * + out_str: Appends 5 bytes to the output buffer. 
 * 1. Append 1 byte to indicate that we're returning a string
 * 2. Append 4 bytes indicating the length of our string
 * 
 * We create similar functions for outputting an integer, a double, an error, etc.
 * Notice that when outputting an array, we're outputting an indicator that the next thing is 
 * an array, alongside the number of elements in said array! The tag-length-value pattern is 
 * a pretty clever technique.
 */
// append serialized data types to the back
static void out_nil(Buffer &out) {
  buf_append_u8(out, TAG_NIL);
}
static void out_str(Buffer &out, const char *s, size_t size) {
  buf_append_u8(out, TAG_STR);
  buf_append_u32(out, (uint32_t)size);
  buf_append(out, (const uint8_t *)s, size);
}
static void out_int(Buffer &out, int64_t val) {
  buf_append_u8(out, TAG_INT);
  buf_append_i64(out, val);
}
static void out_dbl(Buffer &out, double val) {
  buf_append_u8(out, TAG_DBL);
  buf_append_dbl(out, val);
}
static void out_err(Buffer &out, uint32_t code, const std::string &msg) {
  buf_append_u8(out, TAG_ERR);
  buf_append_u32(out, code);
  buf_append_u32(out, (uint32_t)msg.size());
  buf_append(out, (const uint8_t *)msg.data(), msg.size());
}
static void out_arr(Buffer &out, uint32_t n) {
  buf_append_u8(out, TAG_ARR);
  buf_append_u32(out, n);
}

// +--------+---------+
// | status | data... |
// +--------+---------+
struct Response {
    /**
     * - status: Will be associated With the status of the response.
     * - The stream of bytes that we're showing in the response. 
     */
    uint32_t status = 0;
    std::vector<uint8_t> data;
};

/**
 * Global state. We're using an anonymous struct, but the main idea is that we're defining a single
 * static global variable named g_data. 
 */
static struct {
    HMap db;    // top-level hashtable
} g_data;


/**
 * This struct represents a key-value pair for the top-level hashtable. Here we use the idea 
 * of intrusive data structures explained in our notes. Basically this is the struct that 
 * has the data, and the intrusive data structure is used for traversals. 
 * 
 * From our discussions, we'll remember that with intrusive data structures, the Entry (container)
 * is the only thing that's going to be dynamically allocated. As long as its dynamically allocated the HNode 
 * and any pointers that are pointing to it should still work because the memory will still exist. 
 * 
 * However once you free entry, that's going to free all of its data, and pointers pointing to it will no longer work.
 * The takeaway is that Entry is the only one that's using heap memory, the rest should be using stack memory. 
 */
struct Entry {
    struct HNode node;  // hashtable node
    std::string key; 
    std::string val;
};

/**
 * equality comparison for `struct Entry`.
 * 
 * We use that pointer arithmetic to transform these HNode* to Entry*. Two entries are equal 
 * when they have equal keys. 
 */
static bool entry_eq(HNode *lhs, HNode *rhs) {
    struct Entry *le = container_of(lhs, struct Entry, node);
    struct Entry *re = container_of(rhs, struct Entry, node);
    return le->key == re->key;
}

/**
 * A string hashing function based on the FNV (Fowler-Noll-Vo) hash algorithm, which is 
 * a simple, fast, and widely used non-cryptographic hashing algorithm. It returns a 32-bit hash value 
 * for a string or byte sequence. 
 * 
 * Step by Step:
 * 1. h is the FNV-1 32-bit offset basis; It's just a constant starting value for the hash. 
 * 2. It's a 32-bit integer even though the function returns a 64 bit integer.
 * 
 * However there is some variation. Normally the FNV-1 or FNV-1a algorithms do:
 *  - FNV-1: hash = hash * prime; hash = hash ^ byte
 *  - FNV-1a: hash = hash ^ byte; hash = hash * prime
 * So this is a variation, not a textbook FNV implementation. 
 * 
 * Note: The return type is a 64bit integer but we actually return 32-bit hash. As a result, the 
 * returned value with be a 64bit integer, but only the lower 32-bits are meaningful, whilst the upper 32-bits 
 * will be zero. 
 */
static uint64_t str_hash(const uint8_t *data, size_t len) {
    uint32_t h = 0x811C9DC5;
    for (size_t i = 0; i < len; i++) {
        h = (h + data[i]) * 0x01000193;
    }
    return h;
}

/**
 * Handles a Redis GET request
 * 
 * Step by Step:
 * 1. Initialize an empty entry object representing our key and set Entry::key to the key from our request.
 * 2. Calculate the hashcode for the key node, which is needed for the hashmap lookup. 
 * 3. Attempt to find node with key in the hashtable.
 * 4. If that node doesn't exist, then set the status for our response to 404 not found and early return.
 * 5. Do pointer arithmetic to get the Entry struct from that node and extract a reference to the value string. 
 * 6. Copy the bytes of that value string into our response::data.
 * 7. Return a response containing the string data
 */
static void do_get(std::vector<std::string> &cmd, Response &out) {
    Entry key;
    key.key.swap(cmd[1]);
    key.node.hcode = str_hash((uint8_t *)key.key.data(), key.key.size());
    HNode *node = hm_lookup(&g_data.db, &key.node, &entry_eq);
    if (!node) {
        out.status = RES_NX;
        return;
    }
    const std::string &val = container_of(node, Entry, node)->val;
    return out_str(out, val.data(), val.size());
}

/**
 * Handle a Redis SET request. 
 * 
 * Step by step:
 * 1. Create an entry with the key that we're setting. 
 * 2. Create the hash code for the node using that key. 
 * 3. Look up the node associated with that key. If that node exists, update the value in its container. 
 *    Else the node wasn't found so allocate new memory and insert a new pair. 
 * 
 * 4. Return the response with null data.
 */
static void do_set(std::vector<std::string> &cmd, Response &) {
    // a dummy `Entry` just for the lookup
    Entry key;
    key.key.swap(cmd[1]);
    key.node.hcode = str_hash((uint8_t *)key.key.data(), key.key.size());
    // hashtable lookup
    HNode *node = hm_lookup(&g_data.db, &key.node, &entry_eq);
    if (node) {
        // found, update the value
        container_of(node, Entry, node)->val.swap(cmd[2]);
    } else {
        // not found, allocate & insert a new pair
        Entry *ent = new Entry();
        ent->key.swap(key.key);
        ent->node.hcode = key.node.hcode;
        ent->val.swap(cmd[2]);
        hm_insert(&g_data.db, &ent->node);
    }
    return out_nil(out);
}

/**
 * Handle a Redis DELETE request.
 * 
 * 1. Create an entry and set its key to be the key for the entry we want to delete.
 * 2. Create hashcode based on that key, and look up the node we want to delete. 
 * 3. If we actually found the node, we'll do pointer arithmetic to calculate the entry 
 * object associated with that node. Then we'll use delete to free the Entry struct. 
 * 4. Return an integer response which will indicate to the user whether we deleted the 
 * entry or not.
 */
static void do_del(std::vector<std::string> &cmd, Response &) {
    // a dummy `Entry` just for the lookup
    Entry key;
    key.key.swap(cmd[1]);
    key.node.hcode = str_hash((uint8_t *)key.key.data(), key.key.size());
    // hashtable delete
    HNode *node = hm_delete(&g_data.db, &key.node, &entry_eq);
    if (node) { // deallocate the pair
        delete container_of(node, Entry, node);
    }
    return out_int(out, node ? 1 : 0);
}

/**
 * A helper function to do_keys(), which lists all of the key's in your Redis store. Then hm_foreach() 
 * invokes the cb_keys ("callback keys") function on each HNode* in our hashmap:
 * 1. Cast our void* into a Buffer*. 
 * 2. Do pointer arithmetic to get the entry struct for each HNode* and extract the key.
 * 3. Copy the key into the output buffer and return true that the operation succeeded I guess.
 * 
 */
static bool cb_keys(HNode *node, void *arg) {
  Buffer &out = *(Buffer *)arg;
  const std::string &key = container_of(node, Entry, node)->key;
  out_str(out, key.data(), key.size());
  return true;
}

static void do_keys(std::vector<std::string> &, Buffer &out) {
  out_arr(out, (uint32_t)hm_size(&g_data.db));
  hm_foreach(&g_data.db, &cb_keys, (void *)&out);
}

/**
 * Entrypoint for making a Redis request.
 * 
 * Parameters: 
 *- cmd: Reference to a vector of strings. We'll be able to directly affect the original vector since we pass the vector. So These are 
 *  the arguments from the request?
 *- out: reference to the response object; same thing directly affect the response object
 * 
 * Algorithm:
 *   1.If there are two args, AND it's a GET request:
 *   2. If there were 3 arguments, it's in the form "SET <key-to-update> <value-update-to>".
 *   3. Else if, we're dealing with a deletion operation we have "del <key-to-delete>".
 *   4. They're using an unknown command.
 * 
 */
static void do_request(std::vector<std::string> &cmd, Response &out) {
    if (cmd.size() == 2 && cmd[0] == "get") {
        return do_get(cmd, out);
    } else if (cmd.size() == 3 && cmd[0] == "set") {
        return do_set(cmd, out);
    } else if (cmd.size() == 2 && cmd[0] == "del") {
        return do_del(cmd, out);
    } else {
        return out_err(out, ERR_UNKNOWN, "unknown command");
    }
}

/*
* This constructs the response:
* 1. Calculate the size of the response. Remember we've created a protocol when we have a message header (4 bytes) and payload (resp.data.size()). 
* 2. Append the response length to the output buffer (4 bytes).
* 3. Append the response status (4 more bytes); cast the uint32_t to a pointer to an array of uint8_t
* 4. Append the response data into the output.
*/
static void make_response(const Response &resp, std::vector<uint8_t> &out) {
    uint32_t resp_len = 4 + (uint32_t)resp.data.size();
    buf_append(out, (const uint8_t *)&resp_len, 4);
    buf_append(out, (const uint8_t *)&resp.status, 4);
    buf_append(out, resp.data.data(), resp.data.size());
}


/**
 * Appends 4 bytes to the message header, creates/reserves space 
 * for us to indicate the size of our data payload.
 */
static void response_begin(Buffer &out, size_t *header) {
  *header = out.size();       // messege header position
  buf_append_u32(out, 0);     // reserve space
}

/**
 * Calculates the size of our response. This seems to calculate the 
 * size of the message paylaod I think.
 */
static size_t response_size(Buffer &out, size_t header) {
  return out.size() - header - 4;
}

/**
 * 
 * 1. Calculate the size of the message
 * 2. If the message payload is too big:
 *  - Add 4 more bytes to it and insert an error indicating the response is too big.
 * 3. Construct the size of the message header 
 * 4. Copy 4 bytes into the message header to indicate its size
 */
static void response_end(Buffer &out, size_t header) {
  size_t msg_size = response_size(out, header);
  if (msg_size > k_max_msg) {
      out.resize(header + 4);
      out_err(out, ERR_TOO_BIG, "response is too big.");
      msg_size = response_size(out, header);
  }
  // message header
  uint32_t len = (uint32_t)msg_size;
  memcpy(&out[header], &len, 4);
}


/**
 * Attempts to parse at least one message worth of data. If there's less, then it's just a partial read, and it'll finish it later. Once it 
 * has all the information need, it will handle the redis request and after send a response.
 */
static bool try_one_request(Conn *conn) {
    // If we don't even have message header, early return
    if (conn->incoming.size() < 4) {
        return false;   // want read
    }

    // Validate that the message's payload is within reason.
    uint32_t len = 0;
    memcpy(&len, conn->incoming.data(), 4);
    if (len > k_max_msg) {
        msg("too long");
        conn->want_close = true;
        return false;   // want close
    }

    // If we don't have header and body stored in-memory, early return
    if (4 + len > conn->incoming.size()) {
        return false;   // want read
    }
    const uint8_t *request = &conn->incoming[4];

    // got one request, do some application logic
    std::vector<std::string> cmd;
    if (parse_req(request, len, cmd) < 0) {
        msg("bad request");
        conn->want_close = true;
        return false;   // want close
    }
    // Construct the beginning, middle, and end of the respones.
    size_t header_pos = 0;
    response_begin(conn->outgoing, &header_pos);
    do_request(cmd, conn->outgoing);
    response_end(conn->outgoing, header_pos);

    // application logic done! remove the request message.
    buf_consume(conn->incoming, 4 + len);

    // Q: Why not just empty the buffer? See the explanation of "pipelining".
    return true;        // success
}

/*
* + handle_write(): Application callback when the socket is writable.
* 
* 1. Write data from our outgoing buffer to the socket, or the OS-managed send buffer.
* 2. If rv < 0, then there's an issue when writing. The error number EAGAIN happens when we pass in a non-blocking socket to our write. It just means that if the OS had continued with the write, 
* it would have been a blocking write, so it returned an error to prevent us from doing that. However for all other errors, it would bea real error.
* 
* So after this, at this point we can assume that we wrote the data from our outgoing buffer to the socket. Anyways remove the sent bytes from the outgoing buffer and if we sent
*  all of our data (buffer's size is 0), then we need to update our intentions for the TCP connection, which will take place on the next event loop iteration. Our connection has no data, 
*  so we want to make sure we read on the next event loop, and not write. 
* 
* However there's a chance that we did a partial write, meaning that we didn't write the 
* entire outgoing buffer to the socket, and in that case, it's implied that the socket 
* stays with its want_write = true to indicate that we still have data to we want to write to the socket.
* 
* Note: In that implied else case, I don't think want_read is set to false explicitly.
*/
static void handle_write(Conn *conn) {
    assert(conn->outgoing.size() > 0);
    ssize_t rv = write(conn->fd, &conn->outgoing[0], conn->outgoing.size());
    if (rv < 0 && errno == EAGAIN) {
        return; // actually not ready
    }
    if (rv < 0) {
        msg_errno("write() error");
        conn->want_close = true;    // error handling
        return;
    }

    // remove written data from `outgoing`
    buf_consume(conn->outgoing, (size_t)rv);

    // update the readiness intention
    if (conn->outgoing.size() == 0) {   // all data written
        conn->want_read = true;
        conn->want_write = false;
    } // else: want write
}

// application callback when the socket is readable
static void handle_read(Conn *conn) {
    /*
    Q: This buffer is kind of a random size? 64 KB?
    
    Here we're reading bytes from the socket (OS-managed incoming buffer) and we're 
    putting it in the buffer we define here. We're handling the cases where we 
    got an error:
      - EAGAIN: OS realizes that continuing to read from the buffer would be blocking so it stops us and raises this error. In this case the good course of action is to early return, and wait until the next iteration of the event loop to try to read again.
      - Or we could have gotten a real read error. In this case, we should mark the connection to be closed.

    We also handle the case when we the client closes the connection. rv = 0 indicates an EOF. We can reason that if our incoming buffer has 0 data, then the client is done talking. Else, we can reason that we had an unexpected EOF.
    */
    uint8_t buf[64 * 1024];
    ssize_t rv = read(conn->fd, buf, sizeof(buf));
    if (rv < 0 && errno == EAGAIN) {
        return; // actually not ready
    }
    // handle IO error
    if (rv < 0) {
        msg_errno("read() error");
        conn->want_close = true;
        return; // want close
    }
    // handle EOF
    if (rv == 0) {
        if (conn->incoming.size() == 0) {
            msg("client closed");
        } else {
            msg("unexpected EOF");
        }
        conn->want_close = true;
        return; // want close
    }
    // got some new data
    buf_append(conn->incoming, buf, (size_t)rv);

    // parse requests and generate responses
    while (try_one_request(conn)) {}
    // Q: Why calling this in a loop? See the explanation of "pipelining".

    // update the readiness intention
    if (conn->outgoing.size() > 0) {    // has a response
        conn->want_read = false;
        conn->want_write = true;
        // The socket is likely ready to write in a request-response protocol,
        // try to write it without waiting for the next iteration.
        return handle_write(conn);
    }   // else: want read
}

int main() {
    // the listening socket
    int fd = socket(AF_INET, SOCK_STREAM, 0);
    if (fd < 0) {
        die("socket()");
    }
    int val = 1;
    setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &val, sizeof(val));

    // bind
    struct sockaddr_in addr = {};
    addr.sin_family = AF_INET;
    addr.sin_port = ntohs(1234);
    addr.sin_addr.s_addr = ntohl(0);    // wildcard address 0.0.0.0
    int rv = bind(fd, (const sockaddr *)&addr, sizeof(addr));
    if (rv) {
        die("bind()");
    }

    // set the listen fd to nonblocking mode
    fd_set_nb(fd);

    // listen
    rv = listen(fd, SOMAXCONN);
    if (rv) {
        die("listen()");
    }


     /*
    - **fd_to_connection:** Array of connection objects representing TCP connection sockets. These are defined outside the event loop, which means that a given TCP connection
     may need multiple event loops to be "completed" (for the request to be fully read and response to be fully written). This makes sense because we may need to multiple loops 
     to fully read their message, and of course multiple writes to do it as well. Each connection object of course has the file descriptor (mapped to the socket/open resource), 
     but also booleans indicating our intention with the socket, whether we want to read, write, or even close the socket (due to error or if we're actually done processing it).
    
    - **poll_args:** Remember that each socket has a sender and receiver buffer managed by the OS. If the buffer is empty and we try to read from it, then linux will make our main 
    thread wait until there is data. Again this is blocking IO, as whilst we're waiting for data, there could be other sockets that are already ready to go to read or write. This 
    poll_args array is part of the solution, as it's here to detect which sockets are ready for reading or writing, allowing us to avoid that blocking aspect, where the OS makes us 
    BLOCKS for the receive buffer to have data or the send buffer to not be full. 

    Of course, the other part of the solution is to make sure all of our sockets are marked as nonblocking. If the socket is marked as non-blocking and reading data from the socket 
    would actually block the system, it'd raise an error (set errno) to EAGAIN or EWOULDBLOCK to warn us that the read would block our main thread. This is very helpful as it helps us 
    avoid being blocked. However moving back to the poll objects, the first check we're doing is checking the poll::revents bitmasks to see if a socket is ready for reading or writing. 
    You'll see later that in our handle_read() and handle_write() will have those errno=EAGAIN as the second check. I'm guessing that this is needed because those microseconds between 
    the poll() and the handle_read() there could be some interruptions or things in the internal OS that could cause that previously approved non-blocking read, to temporarily become blocking. 
    I guess we're just dealing with race conditions.

    The zeroth index of this will be the listening socket that checks whether we have new TCP connections that we can accept. Remember that TCP connections are stored in an OS-managed queue 
    (for that particular listening socket). If we call accept() AND our listening socket is marked as BLOCKING, and the queue of pending is empty, it'll BLOCK the main thread and wait 
    until there's a new connection. Obviously that's not good as some connection sockets could be ready, but we're still waiting on them. However, this is solved, we'll set the socket to
    non-blocking, so if there are no connections, we'll get an EAGAIN error. 

    Back to poll_args, the zeroth index contains a poll structure for tracking the status of the listening socket. Then all other poll objects will contain the statuses of the TCP connection 
    sockets to see if they're ready for reading, writing, or whether the socket ran into an error. The idea with this is that on every iteration of the event loop, we're going to create new 
    poll objects for all our sockets, and then monitor all of those sockets for their readiness states. This is the only time our code is BLOCKED, but it's blocked efficiently as there's nothing
     else we need to do. As soon as it finds a socket that's ready for IO, stop waiting. Lastly we have two things we want to do:
      1. Check the results of the poll object for the listening socket to see if it's ready for reading, meaning there's a TCP connection socket that we can accept. Then of course handling it.
      2. Check the results of the poll objects for each of the TCP connection sockets. If the poll indicates the socket is ready for IO, then perform IO on the socket.
    Once that's done the next loop begins. Note that on each loop we reset the poll_args array. This makes sense as you're starting off with a clean slate for the statuses, then track those statuses, etc. 

    
    - **The Event Loop:** Then start the event loop. Here's the basic overview of the event loop:
    While running:
      1. Clear poll args state. Then populate it with the poll objects for the listening socket and the connection sockets.
      2. Wait for readiness, monitor all of those sockets; EFFICIENT BLOCKING
      3. At this point, at least one of the sockets have been marked as ready for IO. So let's processing:
        1. Process the poll object for the listening socket in case its status indicates that it's able to accept a pending TCP connection from the backlog queue. 
        2. Process poll objects for the TCP connection sockets. If their statuses indicate that they're able to read or write, then do that reading or writing.
        3. For any poll objects that got an error when checking the IO statuses for a socket OR the connection object has been marked to be closed, then close/delete the connection. This
         involves not only using close() to close the socket associated with that fd, nullify it in the array of connections, and freeing the memory associated with the struct. 
    */
    std::vector<Conn *> fd2conn;
    std::vector<struct pollfd> poll_args;
    while (true) {
        
        // 1. Clears poll objects, and creates new ones
        // First is listening socket and rest are connection sockets. 
        poll_args.clear();
        struct pollfd pfd = {fd, POLLIN, 0};
        poll_args.push_back(pfd);
        for (Conn *conn : fd2conn) {
            if (!conn) {
                continue;
            }
            struct pollfd pfd = {conn->fd, POLLERR, 0};
            if (conn->want_read) {
                pfd.events |= POLLIN;
            }
            if (conn->want_write) {
                pfd.events |= POLLOUT;
            }
            poll_args.push_back(pfd);
        }

        // 2. wait for readiness; monitor all sockets; return immediately if IO is ready for at least one socket
        int rv = poll(poll_args.data(), (nfds_t)poll_args.size(), -1);
        if (rv < 0 && errno == EINTR) {
            continue;   // not an error
        }
        if (rv < 0) {
            die("poll");
        }

        // handle the listening socket
        if (poll_args[0].revents) {
            if (Conn *conn = handle_accept(fd)) {
                // put it into the map
                if (fd2conn.size() <= (size_t)conn->fd) {
                    fd2conn.resize(conn->fd + 1);
                }
                assert(!fd2conn[conn->fd]);
                fd2conn[conn->fd] = conn;
            }
        }

        // handle connection sockets
        for (size_t i = 1; i < poll_args.size(); ++i) { // note: skip the 1st
            uint32_t ready = poll_args[i].revents;
            if (ready == 0) {
                continue;
            }

            Conn *conn = fd2conn[poll_args[i].fd];
            if (ready & POLLIN) {
                assert(conn->want_read);
                handle_read(conn);  // application logic
            }
            if (ready & POLLOUT) {
                assert(conn->want_write);
                handle_write(conn); // application logic
            }

            // close the socket from socket error or when our application logic has marked it for closing
            if ((ready & POLLERR) || conn->want_close) {
                (void)close(conn->fd);
                fd2conn[conn->fd] = NULL;
                delete conn;
            }
        }   // for each connection sockets
    }   // the event loop
    return 0;
}